{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer Churn Prediction using Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIg0IUTVSEK3FRyQarWNNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fiqhrimuliandaputra/Customer-Churn-Prediction-using-Machine-Learning/blob/main/Customer_Churn_Prediction_using_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_vREg2GUWYC"
      },
      "source": [
        "Langkah yang akan dilakukan adalah,\r\n",
        "\r\n",
        "Melakukan Exploratory Data Analysis\r\n",
        "Melakukan Data Pre-Processing\r\n",
        "Melakukan Pemodelan Machine Learning\r\n",
        "Menentukan Model Terbaik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDtDXZ03UeVd"
      },
      "source": [
        "Library yang Digunakan\r\n",
        "Pada analisis kali ini, akan digunakan beberapa package yang membantu kita dalam melakukan analisis data,\r\n",
        "\r\n",
        "Pandas (Python for Data Analysis) adalah library Python yang fokus untuk proses analisis data seperti manipulasi data, persiapan data, dan pembersihan data.\r\n",
        "read_csv() digunakan untuk membaca file csv\r\n",
        "replace() digunakan untuk mengganti nilai\r\n",
        "value_counts() digunakan untuk mengitung unik dari kolom\r\n",
        "drop() digunakan untuk menghapus\r\n",
        "describe() digunakan untuk melihat deskripsi datanya\r\n",
        "value_counts() digunakan untuk mengitung unik dari kolom\r\n",
        "Matplotlib adalah library Python yang fokus pada visualisasi data seperti membuat plot grafik. Matplotlib dapat digunakan dalam skrip Python, Python dan IPython shell, server aplikasi web, dan beberapa toolkit graphical user interface (GUI) lainnya.\r\n",
        "figure() digunakan untuk membuat figure gambar baru\r\n",
        "subplots()digunakan untuk membuat gambar dan satu set subplot\r\n",
        "title()digunakan untuk memberi judul pada gambar\r\n",
        "ylabel()digunakan untuk memberi label sumbu Y pada gambar\r\n",
        "xlabel()digunakan untuk memberi label sumbu Y pada gambar\r\n",
        "pie()digunakan untuk membuat pie chart\r\n",
        "Seaborn membangun plot di atas Matplotlib dan memperkenalkan tipe plot tambahan. Ini juga membuat plot Matplotlib tradisional Anda terlihat lebih cantik.\r\n",
        "\r\n",
        "countplot() digunakan untuk membuat plot dengan jumlah pengamatan di setiap bin kategorik variable\r\n",
        "heatmap() Plot rectangular data as a color-encoded matrix\r\n",
        "Scikit-learn adalah library dalam Python yang menyediakan banyak algoritma Machine Learning baik untuk Supervised, Unsupervised Learning, maupun digunakan untuk mempreparasi data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btfmh9lG_4fB"
      },
      "source": [
        "#Importing General packages\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "import pickle\r\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKY_8DjCUVjO"
      },
      "source": [
        "Data yang DIgunakan\r\n",
        "Untuk Dataset yang digunakan sudah disediakan dalam format csv, silahkan baca melalui fungsi pandas di python df_load = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/dqlab_telco_final.csv')\r\n",
        "\r\n",
        " \r\n",
        "Untuk detil datanya adalah sebagai berikut:\r\n",
        "\r\n",
        "UpdatedAt Periode of Data taken\r\n",
        "customerID Customer ID\r\n",
        "gender Whether the customer is a male or a female (Male, Female)\r\n",
        "SeniorCitizen Whether the customer is a senior citizen or not (Yes, No)\r\n",
        "Partner Whether the customer has a partner or not (Yes, No)\r\n",
        "tenure Number of months the customer has stayed with the company\r\n",
        "PhoneService Whether the customer has a phone service or not (Yes, No)\r\n",
        "InternetService Customer’s internet service provider (Yes, No)\r\n",
        "StreamingTV Whether the customer has streaming TV or not (Yes, No)\r\n",
        "PaperlessBilling Whether the customer has paperless billing or not (Yes, No)\r\n",
        "MonthlyCharges The amount charged to the customer monthly\r\n",
        "TotalCharges The total amount charged to the customer\r\n",
        "Churn Whether the customer churned or not (Yes, No)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93OiYzn-Uu8Z"
      },
      "source": [
        "File Unloading\r\n",
        "Lakukan import dataset ke dalam workspace dengan menggunakan read_csv dan tampilkan juga bentuk atau shape dari dataset tersebut beserta 5 data teratas. \r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "sumber dataset : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/dqlab_telco_final.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JncbwkvNVD8r"
      },
      "source": [
        "#import dataset\r\n",
        "df_load = ___\r\n",
        "\r\n",
        "#Tampilkan bentuk dari dataset\r\n",
        "print(___)\r\n",
        "\r\n",
        "#Tampilkan 5 data teratas\r\n",
        "print(___)\r\n",
        "\r\n",
        "#Tampilkan jumlah ID yang unik\r\n",
        "print(df_load.customerID.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzKvTpweUpq2"
      },
      "source": [
        "df_load = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/dqlab_telco_final.csv')\r\n",
        "print(df_load.shape)\r\n",
        "print(df_load.head())\r\n",
        "print(df_load.customerID.nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Z9UJG8VOXf"
      },
      "source": [
        "Exploratory Data Analysis\r\n",
        "Exploratory Data Analysis memungkinkan analyst memahami isi data yang digunakan, mulai dari distribusi, frekuensi, korelasi dan lainnya. Pada umumnya EDA dilakukan dengan beberapa cara:\r\n",
        "\r\n",
        "Univariat Analysis — analisis deskriptif dengan satu variabel.\r\n",
        "Bivariat Analysis — analisis relasi dengan dua variabel yang biasanya dengan target variabel.\r\n",
        "Multivariat Analysis — analisis yang menggunakan lebih dari atau sama dengan tiga variabel.\r\n",
        "Dalam kasus ini, kamu diminta untuk melihat persebaran dari:\r\n",
        "\r\n",
        "Prosentase persebaran data Churn dan tidaknya dari seluruh data\r\n",
        "Persebarang data dari variable predictor terhadap label (Churn)\r\n",
        "Lakukan import matplotlib dan seaborn\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N270yNSuVTyb"
      },
      "source": [
        "#import matplotlib dan seaborn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3aeHhY4VdQJ"
      },
      "source": [
        "Memvisualisasikan Prosentase Churn\r\n",
        "Kita ingin melihat visualisasi data secara univariat terkait prosentase data churn dari pelanggan. Gunakan fungsi value_counts() untuk menghitung banyaknya unik dari sebuah kolom, pie() untuk membuat pie chart\r\n",
        "\r\n",
        "Berikut adalah hasil yang seharusnya dihasilkan :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxLPwGkTWM8o"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "#Your codes here\r\n",
        "fig = ___\r\n",
        "ax = fig.___\r\n",
        "ax.___('equal')\r\n",
        "labels = ___\r\n",
        "churn = ___.___.___\r\n",
        "ax.___(___, labels=___, autopct=___)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL5S96r5Vxcd"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "#Your codes here\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_axes([0,0,1,1])\r\n",
        "ax.axis('equal')\r\n",
        "labels = ['Yes','No']\r\n",
        "churn = df_load.Churn.value_counts()\r\n",
        "ax.pie(churn, labels=labels, autopct='%.0f%%')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIQk5f8WZH_"
      },
      "source": [
        "Exploratory Data Analysis (EDA) Variabel Numerik\r\n",
        "Hal yang akan kita lakukan selanjutnya adalah memilih variable predictor yang bersifat numerik dan membuat plot secara bivariat, kemudian menginterpretasikannya\r\n",
        "\r\n",
        "Gunakan data `df_load` untuk di olah di tahap ini dan gunakan fungsi `subplots()` untuk membuat gambar dan satu set subplot.\r\n",
        "\r\n",
        "Codingan yang tepat akan menghasilkan output sebagai berikut.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsVL3blHWbsZ"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "#creating bin in chart\r\n",
        "numerical_features = [____]\r\n",
        "fig, ax = plt.subplots(1, ___, figsize=(15, 6))\r\n",
        "# Use the following code to plot two overlays of histogram per each numerical_features, use a color of blue and orange, respectively\r\n",
        "___[___.___ == ___][___].hist(bins=___, color=___, alpha=0.5, ax=___)\r\n",
        "___\r\n",
        "plt.___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A71vwTo9Wi8O"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "#creating bin in chart\r\n",
        "numerical_features = ['MonthlyCharges','TotalCharges','tenure']\r\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\r\n",
        "# Use the following code to plot two overlays of histogram per each numerical_features, use a color of blue and orange, respectively\r\n",
        "df_load[df_load.Churn == 'No'][numerical_features].hist(bins=20, color='blue', alpha=0.5, ax=ax)\r\n",
        "df_load[df_load.Churn == 'Yes'][numerical_features].hist(bins=20, color='orange', alpha=0.5, ax=ax)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xp0zTBQWpTt"
      },
      "source": [
        "Exploratory Data Analysis (EDA) Variabel Kategorik\r\n",
        "Setelah itu, kita akan melakukan pemilihan variable predictor yang bersifat kategorik dan membuat plot secara bivariat, kemudian menginterpretasikannya\r\n",
        "\r\n",
        "Gunakan data `df_load` untuk di olah di tahap ini. Gunakan fungsi `countplot()` untuk membuat plot dengan jumlah pengamatan di setiap bin kategorik variable\r\n",
        "\r\n",
        "Hasil yang diharapkan adalah sebagai berikut. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uth3KXugXEny"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXVpVRdFWxnI"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns \r\n",
        "sns.set(style='darkgrid')\r\n",
        "# Your code goes here\r\n",
        "___, ax = ___(___, ___, figsize=(14, 12))\r\n",
        "___.___(data=___, ___, hue=___, ax=___)\r\n",
        "___\r\n",
        "___\r\n",
        "___\r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHVNzurYW0wG"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "sns.set(style='darkgrid')\r\n",
        "# Your code goes here\r\n",
        "fig, ax = plt.subplots(3, 3, figsize=(14, 12))\r\n",
        "sns.countplot(data=df_load, x='gender', hue='Churn', ax=ax[0][0])\r\n",
        "sns.countplot(data=df_load, x='Partner', hue='Churn', ax=ax[0][1])\r\n",
        "sns.countplot(data=df_load, x='SeniorCitizen', hue='Churn', ax=ax[0][2])\r\n",
        "sns.countplot(data=df_load, x='PhoneService', hue='Churn', ax=ax[1][0])\r\n",
        "sns.countplot(data=df_load, x='StreamingTV', hue='Churn', ax=ax[1][1])\r\n",
        "sns.countplot(data=df_load, x='InternetService', hue='Churn', ax=ax[1][2])\r\n",
        "sns.countplot(data=df_load, x='PaperlessBilling', hue='Churn', ax=ax[2][1])\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXBZTXV-XNTa"
      },
      "source": [
        "Kesimpulan\r\n",
        "Berdasarkan hasil dan analisa di atas dapat disimpulkan:\r\n",
        "\r\n",
        "pada tahap C.1 dapat kita ketahui bahwa sebaran data secara kesuluruhan customer tidak melakukan churn, dengan detil Churn sebanyak 26% dan No Churn sebanyak 74%.\r\n",
        "pada tahap C.2 dapat kita ketahui bahwa untuk MonthlyCharges ada kecenderungan semakin kecil nilai biaya bulanan yang dikenakan, semakin kecil juga kecenderungan untuk melakukan Churn. Untuk TotalCharges terlihat tidak ada kecenderungan apapun terhadap Churn customers. Untuk tenure ada kecenderungan semakin lama berlangganan customer, semakin kecil kecenderungan untuk melakukan Churn.\r\n",
        "pada tahap C.3 dapat kita ketahui bahwa tidak ada perbedaan yang signifikan untuk orang melakukan churn dilihat dari faktor jenis kelamin (gender) dan layanan telfonnya (PhoneService). Akan tetapi ada kecenderungan bahwa orang yang melakukan churn adalah orang-orang yang tidak memiliki partner (partner: No), orang-orang yang statusnya adalah senior citizen(SeniorCitizen: Yes), orang-orang yang mempunyai layanan streaming TV (StreamingTV: Yes), orang-orang yang mempunyai layanan Internet (internetService: Yes) dan orang-orang yang tagihannya paperless (PaperlessBilling: Yes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YH315F6XXsO"
      },
      "source": [
        "Menghapus Unnecessary Columns dari data\r\n",
        "Selanjutnya kita akan mengapus kolom yang tidak akan diikutsertakan dalam pemodelan, kemudian simpan dengan nama cleaned_df. Tampilkan 5 rows teratas nya.\r\n",
        "\r\n",
        "Gunakan drop() untuk menghapus kolom dari suatu data\r\n",
        " \r\n",
        "Hasil yang akan ditampilkan adalah sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54U3OrmtXaX0"
      },
      "source": [
        "#Remove the unnecessary columns customerID & UpdatedAt\r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHcWLj1cXcXL"
      },
      "source": [
        "#Remove the unnecessary columns customerID & UpdatedAt\r\n",
        "cleaned_df = df_load.drop(['customerID','UpdatedAt'], axis=1)\r\n",
        "print(cleaned_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgansvNmXi4_"
      },
      "source": [
        "Encoding Data\r\n",
        "Gunakan data dari hasil dan analisa sebelumnya cleaned_df, untuk merubah value dari data yang masih berbentuk string untuk diubah ke dalam bentuk numeric menggunakan LabelEncoder(). Gunakan describe() untuk melihat deskripsi datanya.\r\n",
        "\r\n",
        "Barikut adalah hasilnya :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlsRvlHGXoQw"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "#Convert all the non-numeric columns to numerical data types\r\n",
        "for column in ___:\r\n",
        "\tif ___.___ == np.___: continue\r\n",
        "    # Perform encoding for each non-numeric column\r\n",
        "    ___ = ___\r\n",
        "print(___)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gA39WbXq0d"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "#Convert all the non-numeric columns to numerical data types\r\n",
        "for column in cleaned_df.columns:\r\n",
        "if cleaned_df[column].dtype == np.number: continue\r\n",
        "# Perform encoding for each non-numeric column\r\n",
        "cleaned_df[column] = LabelEncoder().fit_transform(cleaned_df[column])\r\n",
        "print(cleaned_df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcMpWxrlXwtT"
      },
      "source": [
        "Splitting Dataset\r\n",
        "Gunakan data dari hasil dan analisa sebelumnya cleaned_df, untuk dibagi datasetnya menjadi 2 bagian (70% training & 30% testing) berdasarkan variable predictor (X) dan targetnya (Y). Gunakan train_test_split() untuk membagi data tersebut. Sertakan value_counts untuk mengecek apakah pembagian sudah sama proporsinya. Simpan hasil spliting data menjadi x_train, y_train, x_test & y_test\r\n",
        "\r\n",
        "Hasil yang diharapkan adalah sebagai berikut :\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS5Hn-mEX4fs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "# Predictor dan target\r\n",
        "X = ___\r\n",
        "y = ___\r\n",
        "# Splitting train and test\r\n",
        "___, ___, ___, ___ = ___(___, ___, ____, ___=42)\r\n",
        "# Print according to the expected result\r\n",
        "___\r\n",
        "___\r\n",
        "print(___.___(___))\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGDekiyVX77u"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "# Predictor dan target\r\n",
        "X = cleaned_df.drop('Churn', axis = 1)\r\n",
        "y = cleaned_df['Churn']\r\n",
        "# Splitting train and test\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
        "# Print according to the expected result\r\n",
        "print('Jumlah baris dan kolom dari x_train adalah:', x_train.shape,', sedangkan Jumlah baris dan kolom dari y_train adalah:', y_train.shape)\r\n",
        "print('Prosentase Churn di data Training adalah:')\r\n",
        "print(y_train.value_counts(normalize=True))\r\n",
        "print('Jumlah baris dan kolom dari x_test adalah:', x_test.shape,', sedangkan Jumlah baris dan kolom dari y_test adalah:', y_test.shape)\r\n",
        "print('Prosentase Churn di data Testing adalah:')\r\n",
        "print(y_test.value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26-F91cdYIcC"
      },
      "source": [
        "Kesimpulan\r\n",
        "Setelah kita analisis lebih lanjut, ternyata ada kolom yang tidak dibutuhkuan dalam model, yaitu Id Number pelanggannya (customerID) & periode pengambilan datanya (UpdatedAt), maka hal ini perlu dihapus. Kemudian kita lanjut mengubah value dari data yang masih berbentuk string menjadi numeric melalui encoding, setelah dilakukan terlihat di persebaran datanya khususnya kolom min dan max dari masing masing variable sudah berubah menjadi 0 & 1. Tahap terakhir adalah membagi data menjadi 2 bagian untuk keperluan modelling, setelah dilakukan terlihat dari jumlah baris dan kolom masing-masing data sudah sesuai & prosentase kolom churn juga sama dengan data di awal, hal ini mengindikasikan bahwasannya data terpisah dengan baik dan benar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKiyLQCLYVcR"
      },
      "source": [
        "Pembuatan Model\r\n",
        "Selanjutnya kita akan membuat model dengan menggunakan Algoritma Logistic Regression.\r\n",
        "\r\n",
        "Gunakan LogisticRegression() memanggil algoritma tersebut, fit ke data train dan simpan sebagai log_model\r\n",
        " \r\n",
        "Output dari codingan pada tahap ini adalah sebagai berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p38xyAJiYMvg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "___\r\n",
        "print('Model Logistic Regression yang terbentuk adalah: \\n', ___)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llq_aVxIYZT0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "log_model = LogisticRegression().fit(x_train, y_train)\r\n",
        "print('Model Logistic Regression yang terbentuk adalah: \\n',log_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDltRDi-YaGh"
      },
      "source": [
        "Performansi Model Training - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data training seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "Output pada tahap ini adalah sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KptdHpqZYxEQ"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_train_pred = ___\r\n",
        "# Print classification report \r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGdSXD_7YxWp"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_train_pred = log_model.predict(x_train)\r\n",
        "# Print classification report\r\n",
        "print('Classification Report Training Model (Logistic Regression) :')\r\n",
        "print(classification_report(y_train, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unFQJNz0ZDh5"
      },
      "source": [
        "Performansi Model Training - Menampilkan Plots\r\n",
        "Setelah mendapatkan hasil classification report pada tahap sebelumnya, sekarang kita akan melakukan visualisasi terhadap report tersebut. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G1JaTZ8ZUpI"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqvTBOn-ZVCg"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_train, y_train_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Training Model\\n(Logistic Regression)', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV8uyAuPdSzM"
      },
      "source": [
        "Performansi Data Testing - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data testing seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "Output yang dihasilkan adalah sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGycFP11dTtV"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = ___\r\n",
        "# Print classification report \r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C77LQgUQdY4C"
      },
      "source": [
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = log_model.predict(x_test)\r\n",
        "# Print classification report\r\n",
        "print('Classification Report Testing Model (Logistic Regression):')\r\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIejJVsjhbhw"
      },
      "source": [
        "Performansi Data Testing - Menampilkan Plots\r\n",
        "Setelah menampilkan metrics pada tahap sebelumnya, sekarang kita akan melakukan visualisasi dari metrics yang sudah dihasilkan sebelumnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt31AkEFhYac"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HRa9x22hftj"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_test, y_test_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Testing Model\\n(Logistic Regression)\\n', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbcIl3ychpGk"
      },
      "source": [
        "Kesimpulan\r\n",
        "Dari hasil dan analisa di atas, maka:\r\n",
        "\r\n",
        "Jika kita menggunakan menggunakan algoritma logistic regression dengan memanggil LogisticRegression() dari sklearn tanpa menambahi parameter apapun, maka yang dihasilkan adalah model dengan seting default dari sklearn, untuk detilnya bisa dilihat di dokumentasinya.\r\n",
        "Dari data training terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 80%, dengan detil tebakan churn yang sebenernya benar churn adalah 638, tebakan tidak churn yang sebenernya tidak churn adalah 3237, tebakan tidak churn yang sebenernya benar churn adalah 652 dan tebakan churn yang sebenernya tidak churn adalah 338.\r\n",
        "Dari data testing terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 79%, dengan detil tebakan churn yang sebenernya benar churn adalah 264, tebakan tidak churn yang sebenernya tidak churn adalah 1392, tebakan tidak churn yang sebenernya benar churn adalah 282 dan tebakan churn yang sebenernya tidak churn adalah 146."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYVSaw5nhzqW"
      },
      "source": [
        "Pembuatan Model\r\n",
        "Selanjutnya kita akan membuat model dengan menggunakan Algoritma Random Forest Classifier.\r\n",
        "\r\n",
        "Gunakan RandomForestClassifier() memanggil algoritma tersebut, fit ke data train dan simpan sebagai rdf_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMouXaAnh7_j"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "#Train the model\r\n",
        "___\r\n",
        "print(rdf_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2AgH0a-htjx"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "#Train the model\r\n",
        "rdf_model = RandomForestClassifier().fit(x_train, y_train)\r\n",
        "print(rdf_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2h91WUNiH6h"
      },
      "source": [
        "Performansi Data Training - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data training seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "Output yang dihasilkan adalah sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhIsmDwBiISd"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "y_train_pred = ___\r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SW7hxGniIiF"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "y_train_pred = rdf_model.predict(x_train)\r\n",
        "print('Classification Report Training Model (Random Forest) :')\r\n",
        "print(classification_report(y_train, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE1dB8bylLzS"
      },
      "source": [
        "Performansi Data Training - Menampilkan Plots\r\n",
        "Setelah menampilkan metrics pada tahap sebelumnya, selanjutnya kita akan melakukan visualisasi terhadap metrics tersebut "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iRIg_n2lWYt"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvCsSEcqlWrT"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_train, y_train_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Training Model\\n(Random Forest)', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezRub9UIllwV"
      },
      "source": [
        "Performansi Data Testing - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data testing seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "hasil pada tahap ini adalah sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv-Iw2mIlmkN"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = ___\r\n",
        "# Print classification report \r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV76SQoWlgdx"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = rdf_model .predict(x_test)\r\n",
        "# Print classification report\r\n",
        "print('Classification Report Testing Model (Random Forest Classifier):')\r\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30H62urImYhu"
      },
      "source": [
        "Performansi Data Testing - Menampilkan Plots\r\n",
        "Tampilkan visualisasi dari hasil metrics yang sudah diperoleh pada tahap sebelumnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3YWciyzmZGO"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAf2_5V-mZNt"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_test, y_test_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Testing Model\\n(Random Forest)\\n', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_3RXegXmnDJ"
      },
      "source": [
        "Kesimpulan\r\n",
        "Dari hasil dan analisa di atas, maka:\r\n",
        "\r\n",
        "Jika kita menggunakan menggunakan algoritma Random Forest dengan memanggil RandomForestClassifier() dari sklearn tanpa menambahi parameter apapun, maka yang dihasilkan adalah model dengan seting default dari sklearn, untuk detilnya bisa dilihat di dokumentasinya.\r\n",
        "Dari data training terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 100%, dengan detil tebakan churn yang sebenernya benar churn adalah 1278, tebakan tidak churn yang sebenernya tidak churn adalah 3566, tebakan tidak churn yang sebenernya benar churn adalah 12 dan tebakan churn yang sebenernya tidak churn adalah 9.\r\n",
        "Dari data testing terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 78%, dengan detil tebakan churn yang sebenernya benar churn adalah 262, tebakan tidak churn yang sebenernya tidak churn adalah 1360, tebakan tidak churn yang sebenernya benar churn adalah 284 dan tebakan churn yang sebenernya tidak churn adalah 179."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II5ythezml-v"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "#Train the model\r\n",
        "___\r\n",
        "print(gbt_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc1WRJCKmmg6"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "#Train the model\r\n",
        "gbt_model = GradientBoostingClassifier().fit(x_train, y_train)\r\n",
        "print(gbt_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf5Mb3hIm_CP"
      },
      "source": [
        "Perfomansi Model Data Training - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data training seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "Output yang diharapkan :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WutjWt4lnLD-"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_train_pred = ___\r\n",
        "# Print classification report \r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygGUMXyunLOv"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_train_pred = gbt_model.predict(x_train)\r\n",
        "# Print classification report\r\n",
        "print('Classification Report Training Model (Gradient Boosting):')\r\n",
        "print(classification_report(y_train, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrcjYj-WnU0d"
      },
      "source": [
        "Perfomansi Model Data Training - Menampilkan Plots\r\n",
        "Tampilkan visualisasi dari metrics yang sudah dihasilkan sebelumnya "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77VMqdF8nVC6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-pci0innVMq"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_train, y_train_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Training Model\\n(Gradient Boosting)', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lirvScSenmcK"
      },
      "source": [
        "Performansi Model Data Testing - Menampilkan Metrics\r\n",
        "Setelah kita membuat modelnya, maka lakukan perhitungan untuk memperoleh classification reportnya dan confusion matrixnya di data testing seperti hasil di bawah ini. Gunakan classification_report() & confusion_matrix().\r\n",
        "\r\n",
        "Hasil :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwlyBcp4nm0n"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = ___\r\n",
        "# Print classification report \r\n",
        "___\r\n",
        "___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ppCR_QnlsY"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "# Predict\r\n",
        "y_test_pred = gbt_model.predict(x_test)\r\n",
        "# Print classification report\r\n",
        "print('Classification Report Testing Model (Gradient Boosting):')\r\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkO__xgoDnp"
      },
      "source": [
        "Performansi Model Data Testing - Menampilkan Plots\r\n",
        "Buatlah visualisasi dari metrics yang sudah dihasilkan sebelumnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEg2IQwOoDxm"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = ___((___, ___, ___))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "___\r\n",
        "heatmap = sns.___(___, annot=___, annot_kws={'size': 14}, fmt='d', ___='YlGnBu')\r\n",
        "___.___.set_ticklabels(heatmap.yaxis.___(), rotation=___, ha='right', ___=14)\r\n",
        "___\r\n",
        "\r\n",
        "plt.___(___, fontsize=18, color='darkblue')\r\n",
        "plt.ylabel(___, fontsize=14)\r\n",
        "___\r\n",
        "___.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6AIk3cvoD5U"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Form confusion matrix as a DataFrame\r\n",
        "confusion_matrix_df = pd.DataFrame((confusion_matrix(y_test, y_test_pred)), ('No churn', 'Churn'), ('No churn', 'Churn'))\r\n",
        "\r\n",
        "# Plot confusion matrix\r\n",
        "plt.figure()\r\n",
        "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')\r\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\r\n",
        "\r\n",
        "plt.title('Confusion Matrix for Testing Model\\n(Gradient Boosting)', fontsize=18, color='darkblue')\r\n",
        "plt.ylabel('True label', fontsize=14)\r\n",
        "plt.xlabel('Predicted label', fontsize=14)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6cJ7Oo0oRaW"
      },
      "source": [
        "Kesimpulan\r\n",
        "Dari hasil dan analisa di atas, maka:\r\n",
        "\r\n",
        "Jika kita menggunakan menggunakan algoritma Gradient Boosting dengan memanggil GradientBoostingClassifier() dari package sklearn tanpa menambahi parameter apapun, maka yang dihasilkan adalah model dengan seting default dari sklearn, untuk detilnya bisa dilihat di dokumentasinya.\r\n",
        "Dari data training terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 82%, dengan detil tebakan churn yang sebenernya benar churn adalah 684, tebakan tidak churn yang sebenernya tidak churn adalah 3286, tebakan tidak churn yang sebenernya benar churn adalah 606 dan tebakan churn yang sebenernya tidak churn adalah 289.\r\n",
        "Dari data testing terlihat bahwasannya model mampu memprediksi data dengan menghasilkan akurasi sebesar 79%, dengan detil tebakan churn yang sebenernya benar churn adalah 261, tebakan tidak churn yang sebenernya tidak churn adalah 1394, tebakan tidak churn yang sebenernya benar churn adalah 285 dan tebakan churn yang sebenernya tidak churn adalah 145."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfYQZNdeoouV"
      },
      "source": [
        "Menentukan Algoritma Model Terbaik\r\n",
        "Model yang baik adalah model yang mampu memberikan performa bagus di fase training dan testing model.\r\n",
        "\r\n",
        "Over-Fitting adalah suatu kondisi dimana model mampu memprediksi dengan sangat baik di fase training, akan tetapi tidak mampu memprediksi sama baiknya di fase testing.\r\n",
        "Under-Fitting adalah suatu kondisi dimana model kurang mampu memprediksi dengan baik di fase training, akan tetapi mampu memprediksi dengan baik di fase testing.\r\n",
        "Appropriate-Fitting adalah suatu kondisi dimana model mampu memprediksi dengan baik di fase training maupun di fase testing.\r\n",
        "Untuk detil jelasnya, bisa dilihat di ilustrasi di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MvRGC2eoVtu"
      },
      "source": [
        "print(___)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEKewpv_oWAp"
      },
      "source": [
        "print(log_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23FfOzHcpJhD"
      },
      "source": [
        "Kesimpulan\r\n",
        "Berdasarkan pemodelan yang telah dilakukan dengan menggunakan Logistic Regression, Random Forest dan Extreme Gradiant Boost, maka dapat disimpulkan untuk memprediksi churn dari pelanggan telco dengan menggunakan dataset ini model terbaiknya adalah menggunakan algortima Logistic Regression. Hal ini dikarenakan performa dari model Logistic Regression cenderung mampu memprediksi sama baiknya di fase training maupun testing (akurasi training 80%, akurasi testing 79%), dilain sisi algoritma lainnya cenderung Over-Fitting performanya. Akan tetapi hal ini tidak menjadikan kita untuk menarik kesimpulan bahwsannya jika untuk melakukan pemodelan apapun maka digunakan Logistic Regression, kita tetap harus melakukan banyak percobaan model untuk menentukan mana yang terbaik."
      ]
    }
  ]
}